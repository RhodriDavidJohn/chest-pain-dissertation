{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "533d2ebf",
   "metadata": {},
   "source": [
    "# Feature subset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53a6cf7",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017abda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import logging\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import TunedThresholdClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import(roc_auc_score,\n",
    "                            matthews_corrcoef,\n",
    "                            f1_score,\n",
    "                            precision_recall_curve,\n",
    "                            auc)\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.utils import resample\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not os.getcwd().endswith('chest-pain-dissertation'):\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc120ea",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b87f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filepath: str) -> pd.DataFrame:\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"Data loaded successfully: {filepath}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f582d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath: str):\n",
    "\n",
    "    try:\n",
    "        model = joblib.load(filepath)\n",
    "        print(f\"Model loaded successfully: {filepath}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        msg = f\"Error loading the model {filepath}: {e}\"\n",
    "        print(msg)\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(pipe: Pipeline) -> str:\n",
    "    return list(pipe.named_steps.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_model_name(model_name: str) -> str:\n",
    "\n",
    "    model_name_dict = {\n",
    "        'lreg_model': 'Logistic Regression',\n",
    "        'rfc_model': 'Random Forest',\n",
    "        'xgb_model': 'XGBoost',\n",
    "        'lgbm_model': 'LightGBM',\n",
    "    }\n",
    "    try:\n",
    "        return model_name_dict[model_name]\n",
    "    except:\n",
    "        msg = (f'{model_name} not found. Model name must be one of '\n",
    "               f'{model_name_dict.keys()}')\n",
    "        print(msg)\n",
    "        raise ValueError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175720ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_features(pipe: Pipeline, step_name: str) -> list:\n",
    "\n",
    "    features = pipe.named_steps[step_name].get_feature_names_out()\n",
    "    try:\n",
    "        transformed_features_list = [feature.split('__')[1] for feature in features]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return transformed_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(pipe, X_train, X_test):\n",
    "\n",
    "    logging.getLogger('shap').setLevel(logging.WARNING)\n",
    "\n",
    "    estimator = pipe.estimator\n",
    "\n",
    "    model_name = get_model_name(estimator)\n",
    "\n",
    "    # preprocess the data\n",
    "    X_train_transformed = estimator.named_steps[\"pre_processing\"].transform(X_train)\n",
    "    X_test_transformed = estimator.named_steps[\"pre_processing\"].transform(X_test)\n",
    "\n",
    "    # get feature names\n",
    "    transformed_features = get_model_features(estimator, \"pre_processing\")\n",
    "\n",
    "    X_test_transformed = pd.DataFrame(\n",
    "        data=X_test_transformed, columns=transformed_features\n",
    "    )\n",
    "\n",
    "    # extract the model from the pipeline\n",
    "    ml_model = estimator.named_steps[model_name]\n",
    "\n",
    "    # check if the model has a predict_proba method\n",
    "    if not hasattr(ml_model, \"predict_proba\"):\n",
    "        msg = (f\"{model_name} does not \"\n",
    "               f\"support SHAP explanations. SHAP plot not created.\")\n",
    "        print(msg)\n",
    "        raise Exception(msg)\n",
    "\n",
    "    # initialize SHAP explainer\n",
    "    if model_name=='Logistic Regression':\n",
    "        masker = shap.maskers.Impute(X_train_transformed)\n",
    "        explainer = shap.LinearExplainer(ml_model, masker=masker)\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(ml_model)\n",
    "        \n",
    "    shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "    try:\n",
    "        shap_values = shap_values[:,:,1]\n",
    "    except:\n",
    "        raise Exception(\"Shap values wrong shape\")\n",
    "        \n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20275258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_feature_importance(X_train, transformed_feature_names, shap_values):\n",
    "\n",
    "    feature_base = []\n",
    "    for transformed_feature in transformed_feature_names:\n",
    "        marker = False\n",
    "        for feature in X_train.columns:\n",
    "            if transformed_feature==feature:\n",
    "                feature_base.append(feature)\n",
    "                marker = True\n",
    "        if not marker:\n",
    "            for feature in X_train.columns:\n",
    "                if transformed_feature.startswith(feature):\n",
    "                    feature_base.append(feature)\n",
    "                    marker = True\n",
    "    \n",
    "    df_features = pd.DataFrame(data=[feature_base], columns=transformed_feature_names)\n",
    "    df_shap_values = pd.DataFrame(data=shap_values, columns=transformed_feature_names)\n",
    "\n",
    "    df = pd.concat([df_features, df_shap_values], axis=0)\n",
    "\n",
    "    base_avg_shap_values = []\n",
    "    tran_avg_shap_values = []\n",
    "    base_cols = []\n",
    "    tran_cols = []\n",
    "    for col_idx, col in enumerate(df.columns):\n",
    "        tran_avg = df.iloc[1:, col_idx].abs().mean()\n",
    "        tran_avg_shap_values.append(tran_avg)\n",
    "        tran_cols.append(col)\n",
    "\n",
    "        base_col = df.iloc[0, col_idx]\n",
    "        if base_col not in base_cols:\n",
    "            base_cols.append(base_col)\n",
    "            base_feature_idxs = []\n",
    "            for i, feature in enumerate(feature_base):\n",
    "                if base_col==feature:\n",
    "                    base_feature_idxs.append(i)\n",
    "            base_avg = np.mean(np.abs(df.iloc[1:, base_feature_idxs].values))\n",
    "            base_avg_shap_values.append(base_avg)\n",
    "    \n",
    "    df_base = pd.DataFrame({'feature': base_cols,\n",
    "                            'mean_shap_value': base_avg_shap_values})\n",
    "    df_tran = pd.DataFrame({'transformed_feature': tran_cols,\n",
    "                            'base_feature': feature_base,\n",
    "                            'mean_shap_value': tran_avg_shap_values})\n",
    "    \n",
    "    df_base = df_base.sort_values(by='mean_shap_value', ascending=False).reset_index(drop=True)\n",
    "    df_tran = df_tran.sort_values(by='mean_shap_value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df_base, df_tran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessing_pipeline(X_train, num_cols, disc_cols, cat_cols, removed_features=None):\n",
    "\n",
    "    if removed_features is not None:\n",
    "        num_cols = [col for col in num_cols if col not in removed_features]\n",
    "        disc_cols = [col for col in disc_cols if col not in removed_features]\n",
    "        cat_cols = [col for col in cat_cols if col not in removed_features]\n",
    "        assert len(X_train.columns)==len(num_cols)+len(disc_cols)+len(cat_cols)\n",
    "    \n",
    "    invalid_features = list(\n",
    "        set(num_cols+disc_cols+cat_cols) - set(X_train.columns.values.tolist())\n",
    "    )\n",
    "    if len(invalid_features) != 0:\n",
    "        msg = f\"The following features are not in the dataframe: {invalid_features}\"\n",
    "        print(msg)\n",
    "        raise ValueError(msg)\n",
    "    \n",
    "    impute_and_scale = Pipeline([\n",
    "        (\"numeric_impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"numeric_transformation\", StandardScaler())\n",
    "    ])\n",
    "    binary_and_discrete_impute = Pipeline([\n",
    "        (\"numeric_impute\", SimpleImputer(strategy=\"median\"))\n",
    "    ])\n",
    "    impute_and_one_hot_encode = Pipeline([\n",
    "        (\"categorical_transformation\", OneHotEncoder(handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "\n",
    "    transformers = []\n",
    "    if len(num_cols)>0:\n",
    "        transformers.append(\n",
    "            (\"numeric_preprocessing\", impute_and_scale, num_cols)\n",
    "        )\n",
    "    if len(disc_cols)>0:\n",
    "        transformers.append(\n",
    "            (\"binary_and_discrete_preprocessing\", binary_and_discrete_impute, disc_cols)\n",
    "        )\n",
    "    if len(cat_cols)>0:\n",
    "        transformers.append(\n",
    "            (\"categorical_preprocessing\", impute_and_one_hot_encode, cat_cols)\n",
    "        )\n",
    "\n",
    "    if len(transformers)>0:\n",
    "        return ColumnTransformer(transformers=transformers)\n",
    "    else:\n",
    "        raise Exception(\"There are no transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26000077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(model, X_train, y_train, num_cols, disc_cols, cat_cols, drop_cols):\n",
    "\n",
    "    preprocessor = create_preprocessing_pipeline(X_train, num_cols, disc_cols, cat_cols, drop_cols)\n",
    "\n",
    "    model_params = model.named_steps['rfc_model'].get_params()\n",
    "    \n",
    "    clf = RandomForestClassifier(**model_params)\n",
    "    clf = model.named_steps['rfc_model']\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('pre_processing', preprocessor),\n",
    "        ('rfc_model', clf)\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f970a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probabilitess(pipe, X):\n",
    "    return pipe.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcomes(pipe, X, threshold):\n",
    "    y_prob = predict_probabilitess(pipe, X)\n",
    "    y_pred = y_prob >= threshold\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_bootstrap_metrics(model, X, y, threshold, n_iterations=1000):\n",
    "    roc_auc_scores = []\n",
    "    pr_auc_scores = []\n",
    "    f1_scores = []\n",
    "    g_mean_scores = []\n",
    "    mcc_scores = []\n",
    "\n",
    "    y = np.array(y)\n",
    "\n",
    "    class_0_indices = np.where(y==0)[0]\n",
    "    class_1_indices = np.where(y==1)[0]\n",
    "\n",
    "    n_class_0 = len(class_0_indices)\n",
    "    n_class_1 = len(class_1_indices)\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        \n",
    "        resampled_class_0 = resample(class_0_indices, replace=True, n_samples=n_class_0)\n",
    "        resampled_class_1 = resample(class_1_indices, replace=True, n_samples=n_class_1)\n",
    "\n",
    "        resampled_indices = np.concatenate([resampled_class_0, resampled_class_1])\n",
    "        np.random.shuffle(resampled_indices)\n",
    "\n",
    "        X_resampled = X.iloc[resampled_indices, :]\n",
    "        y_resampled = y[resampled_indices]\n",
    "\n",
    "        y_pred = predict_outcomes(model, X_resampled, threshold)\n",
    "        y_prob = predict_probabilitess(model, X_resampled)\n",
    "\n",
    "        roc_auc = roc_auc_score(y_resampled, y_prob)\n",
    "        precision, recall, _ = precision_recall_curve(y_resampled, y_prob)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        f1 = f1_score(y_resampled, y_pred)\n",
    "        g_mean = geometric_mean_score(y_resampled, y_pred)\n",
    "        mcc = matthews_corrcoef(y_resampled, y_pred)\n",
    "\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        pr_auc_scores.append(pr_auc)\n",
    "        f1_scores.append(f1)\n",
    "        g_mean_scores.append(g_mean)\n",
    "        mcc_scores.append(mcc)\n",
    "\n",
    "    roc_auc_stats = (\n",
    "        np.percentile(roc_auc_scores, 25),\n",
    "        np.percentile(roc_auc_scores, 50),\n",
    "        np.percentile(roc_auc_scores, 75)\n",
    "    )\n",
    "    pr_auc_stats = (\n",
    "        np.percentile(pr_auc_scores, 25),\n",
    "        np.percentile(pr_auc_scores, 50),\n",
    "        np.percentile(pr_auc_scores, 75)\n",
    "    )\n",
    "    f1_stats = (\n",
    "        np.percentile(f1_scores, 25),\n",
    "        np.percentile(f1_scores, 50),\n",
    "        np.percentile(f1_scores, 75)\n",
    "    )\n",
    "    g_mean_stats = (\n",
    "        np.percentile(g_mean_scores, 25),\n",
    "        np.percentile(g_mean_scores, 50),\n",
    "        np.percentile(g_mean_scores, 75)\n",
    "    )\n",
    "    mcc_stats = (\n",
    "        np.percentile(mcc_scores, 25),\n",
    "        np.percentile(mcc_scores, 50),\n",
    "        np.percentile(mcc_scores, 75)\n",
    "    )\n",
    "\n",
    "    return roc_auc_stats, pr_auc_stats, f1_stats, g_mean_stats, mcc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a4969b",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = 'models/rfc_model_full.pkl'\n",
    "train_data_filepath = 'data/model_data/training_data_full.csv'\n",
    "val_data_filepath = 'data/model_data/validation_data_full.csv'\n",
    "test_data_filepath = 'data/model_data/testing_data_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['acute_morbidity_indicator', 'ae_duration_hrs', 'max_tnt_24hr_int',\n",
    "            'min_egfr_24hr_int', 'first_tnt_24hr_int', 'first_egfr_24hr_int',\n",
    "            'mood_and_anxiety_disorders_indicator', 'tnt_egfr_interaction',\n",
    "            'ip_duration_days', 'total_duration_days', 'age', 'tnt_change', 'egfr_change']\n",
    "disc_cols = ['ihd_mi', 'cc_heart_failure', 'cc_myocardial_infarction',\n",
    "             'imd_decile_19', 'qof_diabetes', 'qof_ht', 'ht', 'qof_chd',\n",
    "             'ihd_nonmi', 'af', 'arrhythmia_other', 'stroke', 'hf', 'vasc_dis',\n",
    "             'cardio_other', 'qof_depression', 'qof_mental', 'N_tnt_24hr', 'N_egfr_24hr',\n",
    "             'mi_diagnosis_ae_discharge', 'meds_total', 'meds_antip', 'meds_angio',\n",
    "             'meds_betab', 'meds_total_discharge', 'transfered_dv', 'mi_diagnosis_code',\n",
    "             'chd_diagnosis_code', 'meds_total_more_than_10',\n",
    "             'tnt_rule_in', 'age_threshold', 'ae_target', 'egfr_rule_in']\n",
    "cat_cols = ['ethnicity', 'sex', 'smoking', 'ae_provider', 'ip_provider',\n",
    "            'site_ae', 'site_ip', 'derived_trust_catchment',\n",
    "            'departure_season', 'diagnosis_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca66407",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d4006",
   "metadata": {},
   "source": [
    "### Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = load_model(model_filepath)\n",
    "threshold = rfc_model.best_threshold_\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_csv(train_data_filepath)\n",
    "val_data = load_csv(val_data_filepath)\n",
    "test_data = load_csv(test_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ba5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['nhs_number', 'subsequent_mi_30days_diagnosis'], axis=1).copy()\n",
    "y_train = train_data['subsequent_mi_30days_diagnosis'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_data.drop(['nhs_number', 'subsequent_mi_30days_diagnosis'], axis=1).copy()\n",
    "y_val = val_data['subsequent_mi_30days_diagnosis'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(['nhs_number', 'subsequent_mi_30days_diagnosis'], axis=1).copy()\n",
    "y_test = test_data['subsequent_mi_30days_diagnosis'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7090d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in disc_cols:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_val[col] = X_val[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9de97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_outcomes(rfc_model, X_test, threshold)\n",
    "y_prob = predict_probabilitess(rfc_model, X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "g_mean = geometric_mean_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "main_model_metrics = [roc_auc, pr_auc, f1, g_mean, mcc]\n",
    "\n",
    "print(round(roc_auc, 3))\n",
    "print(round(pr_auc, 3))\n",
    "print(round(f1, 3))\n",
    "print(round(g_mean, 3))\n",
    "print(round(mcc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800e05b",
   "metadata": {},
   "source": [
    "### Order feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = get_shap_values(rfc_model, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29284904",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_feature_names = get_model_features(rfc_model.estimator, 'pre_processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6237d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base, df_tran = order_feature_importance(X_train, transformed_feature_names, shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f07fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_base), len(df_tran))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449aeecf",
   "metadata": {},
   "source": [
    "### Retrain models and store evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07619fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = retrain_model(rfc_model.estimator, X_train, y_train, num_cols, disc_cols, cat_cols, [])\n",
    "y_pred = predict_outcomes(m, X_test, threshold)\n",
    "y_prob = predict_probabilitess(m, X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "g_mean = geometric_mean_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(round(roc_auc, 3))\n",
    "print(round(pr_auc, 3))\n",
    "print(round(f1, 3))\n",
    "print(round(g_mean, 3))\n",
    "print(round(mcc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape, X_train.shape, y_train.shape)\n",
    "print(val_data.shape, X_val.shape, y_val.shape)\n",
    "print(test_data.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model.best_threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84528a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "roc_auc_list = []\n",
    "pr_auc_list = []\n",
    "f1_score_list = []\n",
    "g_mean_list = []\n",
    "mcc_list = []\n",
    "\n",
    "for i, col in enumerate(df_base['feature']):\n",
    "    \n",
    "    feature_list.append(col)\n",
    "    drop_cols = list(set(X_train.columns)-set(feature_list))\n",
    "\n",
    "    X_train_temp = X_train[feature_list].copy()\n",
    "    X_test_temp = X_test[feature_list].copy()\n",
    "    \n",
    "    new_model = retrain_model(rfc_model.estimator, X_train_temp, y_train,\n",
    "                              num_cols, disc_cols, cat_cols, drop_cols)\n",
    "    \n",
    "    stats = stratified_bootstrap_metrics(new_model, X_test_temp, y_test, threshold, 500)\n",
    "\n",
    "    roc_auc_list.append(stats[0])\n",
    "    pr_auc_list.append(stats[1])\n",
    "    f1_score_list.append(stats[2])\n",
    "    g_mean_list.append(stats[3])\n",
    "    mcc_list.append(stats[4])\n",
    "\n",
    "analysis_df = pd.DataFrame({\n",
    "    'Number of Features': range(1, len(feature_list)+1),\n",
    "    'Features': feature_list,\n",
    "    'ROC-AUC': roc_auc_list,\n",
    "    'PR-AUC': pr_auc_list,\n",
    "    'F1-Score': f1_score_list,\n",
    "    'G-Mean': g_mean_list,\n",
    "    'MCC': mcc_list\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0413cb3",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13dfabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_letters = ['(a)', '(b)', '(c)', '(d)', '(e)']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 16))\n",
    "\n",
    "for letter, metric, benchmark, ax in zip(fig_letters, analysis_df.columns.tolist()[2:], main_model_metrics, axs.ravel()):\n",
    "    \n",
    "    ax.axhline(y=benchmark, linestyle='--', color='black', label=f'Main Model {metric} ({benchmark:.3f})')\n",
    "\n",
    "    medians = []\n",
    "    lqs = []\n",
    "    uqs = []\n",
    "    for i in range(len(analysis_df)):\n",
    "        lqs.append(analysis_df.loc[i, metric][0])\n",
    "        medians.append(analysis_df.loc[i, metric][1])\n",
    "        uqs.append(analysis_df.loc[i, metric][2])\n",
    "\n",
    "    ax.plot(analysis_df['Number of Features'], medians, label=f\"Retrained Model Median {metric}\", color='blue')\n",
    "    ax.fill_between(analysis_df['Number of Features'], lqs, uqs, color='blue', alpha=0.2, label=\"IQR (25th-75th percentile)\")\n",
    "\n",
    "    ax.set(title=f\"{letter} {metric} values\",\n",
    "           xlabel=\"Number of Features\",\n",
    "           ylabel=metric)\n",
    "    \n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "ax5 = axs.ravel()[-1]\n",
    "ax5.set_visible(False)\n",
    "\n",
    "fig.suptitle(\"Feature Importance Analysis\", fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.savefig('results/supplementary_results/feature_importance_analysis.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14383c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
