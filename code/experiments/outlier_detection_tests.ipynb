{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     GridSearchCV,\n",
    "                                     TunedThresholdClassifierCV)\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not os.getcwd().endswith('chest-pain-dissertation'):\n",
    "    os.chdir('../')\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bc1fe1",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_size, validation_size, seed):\n",
    "\n",
    "    train_set = int(100*train_size)\n",
    "    val_set = int(100*validation_size)\n",
    "    test_set = int(100*round(1-(train_size+validation_size), 2))\n",
    "\n",
    "    msg = (f\"Splitting data into {train_set}% training set, {val_set}% validation \"\n",
    "           f\"set and {test_set}% testing set...\")\n",
    "    print(msg)\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_set/100, stratify=y, random_state=seed\n",
    "    )\n",
    "    val_size = validation_size/(train_size+validation_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_size, stratify=y_train_val, random_state=seed\n",
    "    )\n",
    "\n",
    "    # save the train-test data for model training and evaluation\n",
    "    training_data = X_train.join(y_train)\n",
    "    validation_data = X_val.join(y_val)\n",
    "    testing_data = X_test.join(y_test)\n",
    "\n",
    "    return training_data, validation_data, testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b66f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessing_pipeline(X_train, num_cols, disc_cols, cat_cols, removed_features=None):\n",
    "\n",
    "    if removed_features is not None:\n",
    "        for feature in removed_features:\n",
    "            if feature in num_cols:\n",
    "                num_cols.remove(feature)\n",
    "            elif feature in disc_cols:\n",
    "                disc_cols.remove(feature)\n",
    "            elif feature in cat_cols:\n",
    "                cat_cols.remove(feature)\n",
    "            else:\n",
    "                print(f\"Feature {feature} is not valid.\")\n",
    "                raise(ValueError((f\"Feature {feature} is not valid. \"\n",
    "                                  f\"Feature must be in {X_train.columns.values.tolist()}\")))\n",
    "        \n",
    "    invalid_features = list(\n",
    "        set(num_cols+disc_cols+cat_cols) - set(X_train.columns.values.tolist())\n",
    "    )\n",
    "    if len(invalid_features) != 0:\n",
    "        msg = f\"The following features are not in the dataframe: {invalid_features}\"\n",
    "        print(msg)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    impute_and_scale = Pipeline([\n",
    "        (\"numeric_impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"numeric_transformation\", StandardScaler())\n",
    "    ])\n",
    "    binary_and_discrete_impute = Pipeline([\n",
    "        (\"numeric_impute\", SimpleImputer(strategy=\"median\"))\n",
    "    ])\n",
    "    impute_and_one_hot_encode = Pipeline([\n",
    "        (\"categorical_transformation\", OneHotEncoder(handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "\n",
    "    transformers = []\n",
    "    if len(num_cols)>0:\n",
    "        transformers.append(\n",
    "            (\"numeric_preprocessing\", impute_and_scale, num_cols)\n",
    "        )\n",
    "    if len(disc_cols)>0:\n",
    "        transformers.append(\n",
    "            (\"binary_and_discrete_preprocessing\", binary_and_discrete_impute, disc_cols)\n",
    "        )\n",
    "    if len(cat_cols)>0:\n",
    "        transformers.append(\n",
    "            (\"categorical_preprocessing\", impute_and_one_hot_encode, cat_cols)\n",
    "        )\n",
    "\n",
    "    if len(transformers)>0:\n",
    "        return ColumnTransformer(transformers=transformers)\n",
    "    else:\n",
    "        raise ValueError(\"No transformaers to create pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(name, X, y, preprocessor, ocsvm_kw=None, iforest_kw=None, lof_kw=None):\n",
    "        \n",
    "    if name=='OCSVM':\n",
    "        clf = OneClassSVM(**(ocsvm_kw or {}))\n",
    "        detector = Pipeline(steps=[('pre_processing', preprocessor), ('outlier_detector', clf)])\n",
    "        detector.fit(X)\n",
    "\n",
    "        outlier_predictions = detector.predict(X)\n",
    "    elif name=='IForest':\n",
    "        clf = IsolationForest(**(iforest_kw or {}))\n",
    "        detector = Pipeline(steps=[('pre_processing', preprocessor), ('outlier_detector', clf)])\n",
    "        detector.fit(X)\n",
    "\n",
    "        outlier_predictions = detector.predict(X)\n",
    "    else: # name=='LOF'\n",
    "        clf = LocalOutlierFactor(**(lof_kw or {}))\n",
    "        detector = Pipeline(steps=[('pre_processing', preprocessor), ('outlier_detector', clf)])\n",
    "        outlier_predictions = detector.fit_predict(X)\n",
    "    \n",
    "    mask = outlier_predictions != -1\n",
    "\n",
    "    return X.loc[mask, :], y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(X, y, model, params, model_desc, model_name, preprocsessing_pipe, k_fold):\n",
    "        \n",
    "        import warnings\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        # set up the pipeline\n",
    "        pipe = Pipeline([\n",
    "            (\"pre_processing\", preprocsessing_pipe),\n",
    "            (model_desc, model)\n",
    "        ])\n",
    "\n",
    "        # set up grid search object\n",
    "        pipe_cv = GridSearchCV(pipe,\n",
    "                               param_grid=params,\n",
    "                               scoring='roc_auc',\n",
    "                               cv=k_fold,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=0,\n",
    "                               error_score=0.0)\n",
    "\n",
    "        # attempt to fit the model\n",
    "        try:\n",
    "            pipe_cv.fit(X, y)\n",
    "        except Exception as e:\n",
    "            msg = (\"The following error occured \"\n",
    "                f\"while tuning {model_name}: {e}\")\n",
    "            print(msg)\n",
    "            raise(e)\n",
    "        \n",
    "        rounded_score = round(pipe_cv.best_score_, 3)\n",
    "\n",
    "        result = {\n",
    "            'model': pipe_cv.best_estimator_,\n",
    "            'params': pipe_cv.best_params_,\n",
    "            'scores': pipe_cv.best_score_\n",
    "        }\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ee95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_threshold(model, model_name, X_val, y_val):\n",
    "\n",
    "    tuned_model = TunedThresholdClassifierCV(\n",
    "        model,\n",
    "        scoring=\"f1\",\n",
    "        cv=\"prefit\",\n",
    "        refit=False,\n",
    "        store_cv_results=True\n",
    "    )\n",
    "\n",
    "    tuned_model.fit(X_val, y_val)\n",
    "\n",
    "    return tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfc399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_auc(model: Pipeline, X_val, y_val) -> float:\n",
    "\n",
    "    y_prob = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_prob)\n",
    "\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f71894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train, X_val, y_val, preprocessor, seed, outlier_name, outlier_prop):\n",
    "\n",
    "    msg = (f\"Training Logistic Regression model using the {outlier_name} \"\n",
    "           f\"outlier detector with assumed {outlier_prop*100}% outliers...\")\n",
    "    print(msg)\n",
    "\n",
    "    model = LogisticRegression(random_state=seed)\n",
    "        \n",
    "    params = {\n",
    "        \"lreg_model__solver\": ['saga', 'liblinear'],\n",
    "        \"lreg_model__penalty\": [None, 'l1', 'l2'],\n",
    "        \"lreg_model__C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"lreg_model__max_iter\": [750, 1000, 1250, 1500]\n",
    "    }\n",
    "    trained_model = tune_hyperparameters(X_train, y_train, model, params, \"lreg_model\", \"Logistic Regression\", preprocessor, 5)\n",
    "        \n",
    "    tuned_model = tune_threshold(trained_model['model'], \"Logistic Regression\", X_val, y_val)\n",
    "    trained_model['model'] = tuned_model\n",
    "\n",
    "    trained_model['scores'] = get_validation_auc(tuned_model, X_val, y_val)\n",
    "\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train, X_val, y_val, preprocessor, seed, outlier_name, outlier_prop):\n",
    "\n",
    "    msg = (f\"Training Random Forest model using the {outlier_name} \"\n",
    "           f\"outlier detector with assumed {outlier_prop*100}% outliers...\")\n",
    "    print(msg)\n",
    "\n",
    "    model = RandomForestClassifier(criterion=\"gini\", max_features=\"sqrt\",\n",
    "                                   random_state=seed)\n",
    "        \n",
    "    params = {\n",
    "        \"rfc_model__n_estimators\": [100, 200, 300, 400],\n",
    "        \"rfc_model__max_depth\": range(5, 15, 2),\n",
    "        \"rfc_model__min_samples_split\": range(16, 25, 2)\n",
    "    }\n",
    "    trained_model = tune_hyperparameters(X_train, y_train, model, params, \"rfc_model\", \"Random Forest\", preprocessor, 5)\n",
    "        \n",
    "    tuned_model = tune_threshold(trained_model['model'], \"Random Forest\", X_val, y_val)\n",
    "    trained_model['model'] = tuned_model\n",
    "\n",
    "    trained_model['scores'] = get_validation_auc(tuned_model, X_val, y_val)\n",
    "        \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82241b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, y_train, X_val, y_val, preprocessor, seed, outlier_name, outlier_prop):\n",
    "\n",
    "    msg = (f\"Training XGBoost model using the {outlier_name} \"\n",
    "           f\"outlier detector with assumed {outlier_prop*100}% outliers...\")\n",
    "    print(msg)\n",
    "\n",
    "    model = XGBClassifier(objective='binary:logistic', seed=seed)\n",
    "        \n",
    "    params = {\n",
    "        \"xgb_model__n_estimators\": [500, 750, 1000],\n",
    "        \"xgb_model__eta\": [0.01, 0.1, 0.3, 0.5],\n",
    "        \"xgb_model__gamma\": [0, 1, 10, 50, 100],\n",
    "        \"xgb_model__max_depth\": [2, 4, 6, 8, 10]\n",
    "    }\n",
    "    trained_model = tune_hyperparameters(X_train, y_train, model, params, \"xgb_model\", \"XGBoost\", preprocessor, 5)\n",
    "        \n",
    "    tuned_model = tune_threshold(trained_model['model'], \"XGBoost\", X_val, y_val)\n",
    "    trained_model['model'] = tuned_model\n",
    "\n",
    "    trained_model['scores'] = get_validation_auc(tuned_model, X_val, y_val)\n",
    "        \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d1eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm(X_train, y_train, X_val, y_val, preprocessor, seed, outlier_name, outlier_prop):\n",
    "\n",
    "    msg = (f\"Training LightGBM model using the {outlier_name} \"\n",
    "           f\"outlier detector with assumed {outlier_prop*100}% outliers...\")\n",
    "    print(msg)\n",
    "\n",
    "    model = LGBMClassifier(objective='binary', random_state=seed)\n",
    "\n",
    "    params = {\n",
    "        \"lgbm_model__num_leaves\": [20, 30, 40],\n",
    "        \"lgbm_model__max_depth\": [2, 5, 10, 15, 20],\n",
    "        \"lgbm_model__learning_rate\": [0.001, 0.01, 0.1],\n",
    "        \"lgbm_model__n_estimators\": [100, 300, 500]\n",
    "    }\n",
    "    trained_model = tune_hyperparameters(X_train, y_train, model, params, \"lgbm_model\", \"LightGBM\", preprocessor, 5)\n",
    "        \n",
    "    tuned_model = tune_threshold(trained_model['model'], \"LightGBM\", X_val, y_val)\n",
    "    trained_model['model'] = tuned_model\n",
    "\n",
    "    trained_model['scores'] = get_validation_auc(tuned_model, X_val, y_val)\n",
    "        \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2044b6",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8195a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean/processed_dataset.csv')\n",
    "X = df.drop(['nhs_number', 'subsequent_mi_30days_diagnosis'], axis=1).copy()\n",
    "y = df['subsequent_mi_30days_diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, _ = split_data(X, y, train_size=0.6, validation_size=0.2, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a17538",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(['subsequent_mi_30days_diagnosis'], axis=1).copy()\n",
    "y_train = train_set['subsequent_mi_30days_diagnosis']\n",
    "\n",
    "X_val = val_set.drop(['subsequent_mi_30days_diagnosis'], axis=1).copy()\n",
    "y_val = val_set['subsequent_mi_30days_diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd1137",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['acute_morbidity_indicator', 'ae_duration_hrs', 'max_tnt_24hr_int',\n",
    "            'min_egfr_24hr_int', 'first_tnt_24hr_int', 'first_egfr_24hr_int',\n",
    "            'mood_and_anxiety_disorders_indicator', 'tnt_egfr_interaction',\n",
    "            'ip_duration_days', 'total_duration_days', 'age', 'tnt_change', 'egfr_change']\n",
    "disc_cols = ['ihd_mi', 'cc_heart_failure', 'cc_myocardial_infarction',\n",
    "             'imd_decile_19', 'qof_diabetes', 'qof_ht', 'ht', 'qof_chd',\n",
    "             'ihd_nonmi', 'af', 'arrhythmia_other', 'stroke', 'hf', 'vasc_dis',\n",
    "             'cardio_other', 'qof_depression', 'qof_mental', 'N_tnt_24hr', 'N_egfr_24hr',\n",
    "             'mi_diagnosis_ae_discharge', 'meds_total', 'meds_antip', 'meds_angio',\n",
    "             'meds_betab', 'meds_total_discharge', 'transfered_dv', 'mi_diagnosis_code',\n",
    "             'chd_diagnosis_code', 'meds_total_more_than_10',\n",
    "             'tnt_rule_in', 'age_threshold', 'ae_target', 'egfr_rule_in']\n",
    "cat_cols = ['ethnicity', 'sex', 'smoking', 'ae_provider', 'ip_provider',\n",
    "            'site_ae', 'site_ip', 'derived_trust_catchment',\n",
    "            'departure_season', 'diagnosis_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_prop_list = [0.0, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "outlier_detector_names = ['OCSVM', 'IForest', 'LOF']\n",
    "n_rows = len(outlier_detector_names)\n",
    "n_cols = 4\n",
    "\n",
    "preprocessor = create_preprocessing_pipeline(X_train, num_cols, disc_cols, cat_cols)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, squeeze=False, figsize=(16, n_rows*4))\n",
    "\n",
    "\n",
    "for outlier_idx, outlier_detector_name in enumerate(outlier_detector_names):\n",
    "    min_idx = outlier_idx*n_cols\n",
    "    max_idx = min_idx+n_cols\n",
    "    \n",
    "    for i, ax in enumerate(axs.ravel()[min_idx:max_idx]):\n",
    "        if i in [0, 4, 8]:\n",
    "            model_name = 'Logistic Regression'\n",
    "        elif i in [1, 5, 9]:\n",
    "            model_name = 'Random Forest'\n",
    "        elif i in [2, 6, 10]:\n",
    "            model_name = 'XGBoost'\n",
    "        elif i in [3, 7, 11]:\n",
    "            model_name = 'LightGBM'\n",
    "    \n",
    "        for idx, outlier_prop in enumerate(outlier_prop_list):\n",
    "            \n",
    "            if outlier_prop==0.0:\n",
    "                X_or = X_train\n",
    "                y_or = y_train\n",
    "            else:\n",
    "                if outlier_detector_name=='OCSVM':\n",
    "                    X_or, y_or = remove_outliers(outlier_detector_name,\n",
    "                                                 X_train,\n",
    "                                                 y_train,\n",
    "                                                 preprocessor,\n",
    "                                                 ocsvm_kw={'nu': outlier_prop})\n",
    "                elif outlier_detector_name=='IForest':\n",
    "                    X_or, y_or = remove_outliers(outlier_detector_name,\n",
    "                                                 X_train,\n",
    "                                                 y_train,\n",
    "                                                 preprocessor,\n",
    "                                                 iforest_kw={'contamination': outlier_prop, 'random_state': seed})\n",
    "                else:\n",
    "                    X_or, y_or = remove_outliers(outlier_detector_name,\n",
    "                                                 X_train,\n",
    "                                                 y_train,\n",
    "                                                 preprocessor,\n",
    "                                                 lof_kw={'contamination': outlier_prop, 'n_neighbors': int(len(X_train)*outlier_prop)})\n",
    "                \n",
    "            if model_name=='Logistic Regression':\n",
    "                model_dict = train_logistic_regression(X_or, y_or, X_val, y_val, preprocessor, seed, outlier_detector_name, outlier_prop)\n",
    "            elif model_name=='Random Forest':\n",
    "                model_dict = train_random_forest(X_or, y_or, X_val, y_val, preprocessor, seed, outlier_detector_name, outlier_prop)\n",
    "            elif model_name=='XGBoost':\n",
    "                model_dict = train_xgboost(X_or, y_or, X_val, y_val, preprocessor, seed, outlier_detector_name, outlier_prop)\n",
    "            else:\n",
    "                model_dict = train_lightgbm(X_or, y_or, X_val, y_val, preprocessor, seed, outlier_detector_name, outlier_prop)\n",
    "\n",
    "            model = model_dict['model']\n",
    "\n",
    "            y_scores = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "            display = RocCurveDisplay.from_predictions(\n",
    "                y_val,\n",
    "                y_scores,\n",
    "                name=f\"{outlier_prop}% outliers\",\n",
    "                ax=ax,\n",
    "                plot_chance_level=(idx==len(outlier_prop_list)-1),\n",
    "                chance_level_kw={'linestyle': ':'}\n",
    "            )\n",
    "        ax.set_title(f'{model_name} - {outlier_detector_name}')\n",
    "_ = plt.tight_layout(pad=2.0)\n",
    "plt.savefig('results/experimentation_results/outliter_detection_results.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5595d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
